\section{Our construction}

We are now ready to outline our map, which is an instantiation of a graded encoding scheme as in prior works \cite{clt, ggh13a, clt15}.  The basic operations (setup, encoding, addition, multiplication) of our scheme are essentially identical to those of the GSW scheme.

In general, a fresh encoding of a plaintext $\mu \in \Rq$ at level-$i$ will look like the following, where $R \leftarrow \{0,1\}^{N\times m}$, $z$ is a random ring element, and $A$ is a GSW public key:
$$C = \flattenfn\left(z^{-i}\mu I_{N} + \bdfn(z^{-\kappa} R\cdot A))\right)$$
Note that encodings are small as they are the result of the $\flattenfn$ function---encodings are the same as GSW ciphertexts except here we introduce the notion of levels through the element $z$ (and we work over a polynomial ring instead of the integers).

\paragraph{Setup: $(\mathsf{pp},\pzt) \leftarrow \mathsf{setup}(1^\lambda, 1^\kappa)$.}  Given the security parameter $\lambda$ and the multilinearity level $\kappa$, we generate the public parameters and the zero-testing element.  The parameters $q$ and $n$ define the ring $\Rq$.  Set $m = O(\log q)$ and $N = 2\ell$ where $\ell = \lceil \log q \rceil$.  Let $\chi$ be an error distribution on $\Rq$.  $\sigma$ is a parameter for sampling plaintext elements from a discrete Gaussian distribution.  We generate the {\bf encoding key} $A$ by drawing $\vec{e} \leftarrow \chi^m$, $\vec{a} \leftarrow \Rq^m$, and $t \leftarrow \Rq$.  Set $\vec{b} = \vec{a}t + \vec{e}$ and $\vec{s} = (1, -t)^T$ and $A = \big(\vec{b} \; \big| \; \vec{a}\big)$.  We generate the {\bf zero-testing parameter} $\pzt$ by first drawing a uniform element $z \leftarrow \Rq$ and then a few ``somewhat small" elements $\alpha \leftarrow \mathcal{D}_{\mathbb{Z}^n, \sigma_\alpha}$, $\vec{\epsilon} \leftarrow (\mathcal{D}_{\mathbb{Z}^n, \sigma_\delta})^N$, and $\vec{\delta} \leftarrow (\mathcal{D}_{\mathbb{Z}^n, \sigma_\epsilon})^N$ for some parameters $\sigma_\alpha, \sigma_\delta,$ and $\sigma_\epsilon$.  We then set $$\pzt = \alpha(z^\kappa\vec{v} + \vec{\delta}) + \vec{\epsilon}$$ where $\vec{v} =  \powfn(\vec{s})$.  Intuitively, $\pzt$ is a vector of $N$ RLWE ``encryptions" of the $N$ coefficients of $\vec{v}$, the original decryption key in GSW.  We generate a level-1 encoding $Y$ by drawing $R \leftarrow \{0,1\}^{N\times m}$ and setting $$Y = \flattenfn(z^{-1}I_N + \bdfn(z^{-\kappa}R\cdot A))$$  which is a level-1 encoding of 1. We generate the rerandomization parameters $X_i$ by drawing $R_i \leftarrow \{0,1\}^{N \times m}$ and setting $$X_i = \flattenfn(\bdfn(z^{-\kappa}R_i\cdot A))$$ for $1 \leq i \leq \tau$.  Note that these are level-1 encodings of 0. We output $\mathsf{pp} = (\kappa, q,n,m,N,\sigma, Y, \{X_i\}_{i=1}^\tau)$ and $\pzt$.

\paragraph{Zero testing:  $\mathsf{isZero}(C, \pzt) \stackrel{?}{=} 0/1$.}  To zero-test a (fresh) encoding $C$ of $\mu$ at level-$\kappa$, compute $\vec{w} = C\cdot \pzt$ and output 1 if $||\vec{w}|| < P$ and 0 otherwise.  To see why this is correct, note that we have:  $$A\vec{s} = \vec{b} - \vec{a}t = \vec{e}$$  Thus, $\bdfn(A)\vec{v} = \vec{e}$ as $\vec{v} = \powfn(\vec{s})$.  Additionally, $\flattenfn(C)\cdot\powfn(\vec{s}) = C\cdot \powfn(\vec{s}) = C\cdot\vec{v}$, so we have:
\begin{align*}
C\cdot \pzt &= \alpha z^\kappa C\vec{v} + C(\alpha\vec{\delta} + \vec{\epsilon})\\
&= \alpha(z^\kappa)(z^{-\kappa}\mu + \bdfn(z^{-\kappa}R\cdot A))\vec{v} + C(\alpha\vec{\delta} + \vec{\epsilon})\\
&= \alpha(z^\kappa)(z^{-\kappa}\mu \vec{v} + \bdfn(z^{-\kappa}R\cdot A)\vec{v}) + C(\alpha\vec{\delta} + \vec{\epsilon})\\
&= \alpha(z^\kappa)(\mu z^{-\kappa}\vec{v} + z^{-\kappa}R\vec{e}) + C(\alpha\vec{\delta} + \vec{\epsilon})\\
&= \alpha(z^\kappa z^{-\kappa})(\mu \vec{v} + R\vec{e}) + C(\alpha\vec{\delta} + \vec{\epsilon})\\
&= \alpha(\mu \vec{v} + R\vec{e}) + C(\alpha\vec{\delta} + \vec{\epsilon})
\end{align*} 

Intuitively, note that this element is large if and only if $\mu \not= 0$ because all elements are small except for $\vec{v}$.  Formally, we prove the following lemma in the appendix.

\begin{lemma}
\label{zerotesting}
This is the lemma that formally outlines the size difference between a zero and nonzero encoding.
\end{lemma}

\paragraph{Addition \& subtraction.}  For two encodings $C_1$ and $C_2$ at the same level-$i$, define the addition and subtraction functions as follows:
\begin{align*}
\mathsf{add}(C_1,C_2) &= \flattenfn(C_1 + C_2)\\
\mathsf{sub}(C_1,C_2) &= \flattenfn(C_1 - C_2)
\end{align*}
As in the GSW scheme, it is clear that these are both correct homomorphic operations with respect to the zero-tester.

\paragraph{Multiplication.}  Suppose that $C_1$ encodes a plaintext $\mu_1$ at level-$i$ and $C_2$ encodes a plaintext $\mu_2$ at level-$j$ with $i+j \leq \kappa$.  Then we define the multiplication operator as follows:

$$\mathsf{mult}(C_1, C_2) = \flattenfn(C_1 \cdot C_2)$$
To see that this is correct suppose that $i+j = \kappa$ (i.e., we can zero-test).  Then:
\begin{align*}
\mathsf{mult}(C_1, C_2)\cdot \pzt &= \alpha (z^\kappa) C_1C_2\vec{v} + \flattenfn(C_1\cdot C_2)(\alpha\vec{\delta} + \vec{\epsilon})\\
&= \alpha (z^\kappa)C_1(z^{-j}\mu_2\vec{v} + z^{-\kappa}\vec{e_2}) + \flattenfn(C_1\cdot C_2)(\alpha\vec{\delta} + \vec{\epsilon})\\
&= \alpha(z^\kappa)(z^{-i-j}\mu_1\mu_2 \vec{v} + \mu_2 z^{-\kappa}\vec{e_1} + z^{-\kappa}C_1\vec{e_2}) \\
&\quad + \flattenfn(C_1\cdot C_2)(\alpha\vec{\delta} + \vec{\epsilon})\\
&= \alpha(z^\kappa z^{-\kappa}) (\mu_1\mu_2 \vec{v} + \mu_2 \vec{e_1} + C_1\vec{e_2}) + \flattenfn(C_1\cdot C_2)(\alpha\vec{\delta} + \vec{\epsilon})\\
&= \alpha (\mu_1\mu_2 \vec{v} + \mu_2 \vec{e_1} + C_1\vec{e_2}) + \flattenfn(C_1\cdot C_2)(\alpha\vec{\delta} + \vec{\epsilon})
\end{align*}
Note that this expression will be small if and only if $\mu_1\mu_2 = 0$ (and $\mu_2$ is also small---as in CLT and GGH, our message space is restricted to control noise growth).

\paragraph{Sampling:  $U \leftarrow \mathsf{samp}(\mathsf{pp})$.}  To sample a level-0 encoding---that is, a plaintext element---simply draw $\mu\leftarrow \mathcal{D}_{\mathbb{Z}^n, \sigma}$ and set $$U = \flattenfn(\mu \cdot I_N)$$

\paragraph{Rerandomization: $C' \leftarrow \mathsf{rerand}(\mathsf{pp}, C)$.}  To rerandomize a level-1 encoding $C$, draw $r_j \leftarrow \{0,1\}$ for $0 \leq j \leq \tau$ and compute $$C' = C + \sum_{j=1}^\tau r_jX_j$$ using the addition operator of the scheme.

\paragraph{Encoding:  $C \leftarrow \mathsf{enc}(\mathsf{pp},U,i)$.}  A user can encode a level-0 encoding $U$ of a plaintext $\mu$ to level-$i$ by first computing $Y' \leftarrow \mathsf{rerand}(\mathsf{pp}, Y)$, which will be a rerandomized level-1 encoding of 1, and then setting $$C = U \cdot \left(Y'\right)^i$$ using the multiplication operator of the scheme, which will be a level-$i$ encoding of $\mu$.

\paragraph{Extraction: $sk \leftarrow \mathsf{ext}(\mathsf{pp}, \pzt, C^{(\kappa)})$.}  As in \cite{ggh13a, clt15} we apply the zero-tester to a level-$\kappa$ encoding $C^{(\kappa)}$ and collect the most significant bits to extract a random function of the underlying plaintext $\mu$.

\begin{lemma}
\label{extraction}
This is the lemma that states we can extract a random function of $\lambda$ bits from a level-$\kappa$ encoding.
\end{lemma}





\subsection{Asymmetric version}

As in CLT and GGH we can instead compute $z_i$ for $i \in [\kappa]$ and encode plaintexts to specific index sets $S \subseteq [\kappa]$ rather than levels.  This is required for some applications like obfuscation.

\subsection{Setting parameters}

As in homomorphic encryption schemes and multilinear maps, the size of the noise at level-$\kappa$ is dependent on the size of the initial error $B_e$, the multilinearity level $\kappa$, and the initial size of plaintexts $B_\mu$.  Specifically, we have the noise bounded by:
\begin{equation}
\label{noise1}
B_\kappa = (nN\cdot B_\mu)^\kappa \cdot B_e
\end{equation}

Then, when we apply the zero-testing element at level-$\kappa$ we have:
\begin{equation}
\label{noise2}
C\pzt = \alpha (\mu \vec{v} + \vec{e_{\circ}} + C\vec{\delta}) + C\vec{\epsilon}
\end{equation}
where the size of $e_{\circ}$ is bounded by $B_\kappa$, as in \eqref{noise1}.  In the case of $\mu = 0$ we then have the size of \eqref{noise2} bounded by $B_\alpha(B_\kappa + nNB_\delta) + nNB_\epsilon$.

\paragraph{Parameters that need to be set.}

\begin{itemize}
\item $n$, the degree of polynomials.  Dependent on RLWE security.
\item $q$, the size of the underlying field.  Dependent on RLWE security and (more importantly) the size of zero-tested elements, which depends on $n, N, \chi, \kappa, \sigma, \sigma_\alpha, \sigma_\delta, \sigma_\epsilon$.
\item $\sigma$, the parameter for the Gaussian that samples plaintexts.  GGH bounds the size of their ciphertexts (not their plaintexts by $q^{1/8}$).
\item $\sigma_\alpha, \sigma_\delta, \sigma_\epsilon$, the parameters for the Gaussians that draw noise elements for the zero-tester.  GGH sets $\sigma_\alpha$ to be $\sqrt{q}$.  Should be ``as large as possible" but obviously cannot yield a uniform distribution.
\item $\chi$, the error distribution for the RLWE instance $A$.
\item $\tau$, the number of encodings of $0$ we publish for rerandomization.
\end{itemize}


